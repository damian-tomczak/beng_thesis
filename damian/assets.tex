\newpage
\subsection{Assets}
\label{sec:assets}
\subsubsection{Models}
\hspace{\parindent}
Models are saved in .obj files, that is a pretty old way of storing models, as nowadays, a more expected format is glTF \cite{gltf}. And all the assets should be stored in binary packages.\\\\
List of models:
\begin{itemize}
    \item polonez.obj \cite{PolonezModel}
    \item sphere.obj
    \item village.obj \cite{VillageModel}
\end{itemize}
\subsubsection{Shaders}
\hspace{\parindent}
So far, the only shaders we support are fragment and vertex shaders - found in section \hyperref[sec:shader_compiler]{\ref*{sec:shader_compiler} Shader Compiler}.\\
Shader structure:
\begin{itemize}
    \item shader.h
    \item shader.vert
    \item shader.frag
\end{itemize}

All the shaders start with a preprocessor section where the version of the shader is defined, and we support only versions 4.5 and above.

Extensions which are enabled: \texttt{GL\_GOOGLE\_include\_directive} makes it possible to add other files to the shader, \texttt{GL\_EXT\_multiview} enables  functionality \textit{"VK\_KHR\_multiview(3) Manual Page"} \cite{multiview}, the last \texttt{GL\_EXT\_debug\_printf} enables printing debug messages from \hyperref[sec:renderdoc]{\ref*{sec:renderdoc} RenderDoc} followed by include declarations:
\begin{lstlisting}[language=c++, caption=Common shader preprocessor]
#version 450
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_multiview : enable
#extension GL_EXT_debug_printf : enable

[Include Section]
\end{lstlisting}
\newpage
As we use single pipeline layout for all the pipelines - \hyperref[sec:renderer]{\ref*{sec:renderer} Renderer}, all the shaders have the same uniform data access across the program (except uniform data sent via push constants, they are sent only for pipelines they are interested in).

The first binding point contains dynamically updated uniform data, which is unique for each model, the model matrix of each of them. The second, contains data common for all the objects displayed on the screen: position of the camera, view matrix for two points of view, and projection matrix, also for two points of view. The last uniform buffer contains information about positions of light sources.

There are two pushed data constants, first used to store position of the object currently being drawn, second for sending material's properties used to draw objects with PBR lighting.
\begin{lstlisting}[language=c++, caption=Common shader data]
layout(binding = 0) uniform IndividualUbo {
    mat4 modelMat;
} individualUbo;

layout(binding = 1) uniform CommonUbo {
    vec3 camPos;
    mat4 viewMats[2];
    mat4 projMats[2];
} commonUbo;

layout (binding = 2) uniform LightsUbo {
    vec3 positions[LIGHTS_N];
} lightsUbo;

layout(push_constant) uniform PushConst {
    vec3 objPos;
} pushConst;

layout(push_constant) uniform Material {
    layout(offset = 16) float r;
    layout(offset = 20) float g;
    layout(offset = 24) float b;
    layout(offset = 32) float roughness;
    layout(offset = 36) float metallic;
} material;
\end{lstlisting}

Shader list:
\begin{itemize}
    \item Shader headers\\
    They are shared between shaders and engine code:
    \begin{itemize}
        \item common.h\\
        Commonly using constants.
\begin{lstlisting}[language=c++, caption=Common used shader constants (./assets/shaders/common.h)]
#define PI 3.14159265359
#define LIGHTS_N 2
\end{lstlisting}
    \item grid.h\\
    As the grid is a plane, to draw it a draw call takes 6 vertices.
\begin{lstlisting}[language=c++, caption=Grid constant (./assets/shaders/grid.h)]
#define GRID_DRAW_CALL_VERTEX_COUNT 6
\end{lstlisting}
    \item light\_cube.h\\
    As the cube consists of 6 planes each consisting of 6 vertices, to draw it a draw call takes 36 vertices.
\begin{lstlisting}[language=c++, caption=Light cubes shader constant (./assets/shaders/light\_cube.h)]
#pragma once

#define LIGHT_CUBE_DRAW_CALL_VERTEX_COUNT 36
\end{lstlisting}
    \item grid\_params.h\\
    This header defines all grid properties which allow for user's modifications to their preferences, with the constant positions of plane vertices and indices.
\begin{lstlisting}[language=c++, caption=Grid shader parameters (./assets/shaders/grid\_params.h)]
const float gridSize = 100.0;
const float gridCellSize = 0.5;
vec4 gridColorThin = vec4(1, 0, 0, 1.0);
vec4 gridColorThick = vec4(0, 1, 0, 1.0);
const float gridMinPixelsBetweenCells = 2.0;

const vec3 pos[4] =
{
    vec3(-1.0, 0.0, -1.0),
    vec3(-1.0, 0.0,  1.0),
    vec3( 1.0, 0.0,  1.0),
    vec3( 1.0, 0.0, -1.0)
};

const int indices[6] = {
    0, 1, 2, 2, 3, 0
};
\end{lstlisting}
    \end{itemize}
    \item grid.vert\\
    As the grid is a plane with "texture" drew during the fragment stage,
    The grid moves with camera position, so every view calculations must be multiplied by camera matrix.
\begin{lstlisting}[language=c++, caption=Grid vertex shader (./assets/shaders/grid.vert)]
layout (location = 0) out vec2 uv;
layout (location = 1) out vec2 camPos;

void main()
{
    mat4 cameraMat = mat4(1.0);
    cameraMat[3] = vec4(ubo.camPos, 1.0);

    mat4 MVP = ubo.projMats[gl_ViewIndex] * ubo.viewMats[gl_ViewIndex] * cameraMat;

    int idx = indices[gl_VertexIndex];
    vec3 position = pos[idx] * gridSize;

    mat4 iViewMat = inverse(ubo.viewMats[gl_ViewIndex] * cameraMat);
    camPos = vec2(iViewMat[3][0], iViewMat[3][2]);

    position.x += camPos.x;
    position.z += camPos.y;

    uv = position.xz;
    gl_Position = MVP * vec4(position, 1.0);
}
\end{lstlisting}
    \item grid.frag\\
    \texttt{dudv} contains the screen space length of derivatives of uv coordinates of the grid. Current LOD of the grid can be calculated by taking into account \texttt{gridMinPixelsBetweenCells}, the value of this variable controls how fast we want our LOD level to increase. Fractional part of the LOD is used as fading factor to render smooth transitions between the adjacent levels. The logarithm base of 10 is used to ensure each next LOD covers at least \texttt{pow(10, lodLevel)} more cells of the previous LOD.\\
    The LOD levels are blended between each other. To render them, we have to calculate the cell size for each LOD. The cell size is essentially the frequency at which a new line should be visible.\\
    To be able to draw antialiased lines using alpha transparency, we need to increase the screen coverage of our lines - to make it, each line must cover up to 4 pixels \texttt{dudv *= 4.0}.\\
    Then coverage alpha value that corresponds to each calculated LOD level of the grid calculating the absolute distances to the cell line centers and pick the maximum coordinate.\\
\begin{equation}
S_{saturate}\left(x\right)=\left\{x>1:1,x<0:0,x\right\}
\end{equation}
\begin{equation}
max\left(1-\operatorname{abs}\left(S_{saturate}\left(\frac{\operatorname{mod}\left(x,c\right)}{\left(w\right)}\right)\cdot2-1\right)\right)
\end{equation}
    Nonzero alpha values represent non-empty transition area of the grid. Let's blend between them using values of \texttt{gridColorThick} and \texttt{gridColorThin} variables.\\
    To make the grid disappear when it is far away from the camera, the value of \texttt{opacityFalloff} is needed.\\
    Finally, blend of the LOD level alpha values and scale the result with the opacity falloff factor can be done \texttt{c.a *= (lod2a > 0.0 ? lod2a : lod1a > 0.0 ? lod1a : (lod0a * (1.0-lodFade))) * opacityFalloff;}
\begin{lstlisting}[language=c++, caption=Grid fragment shader (./assets/shaders/grid.frag)]
layout (location=0) in vec2 uv;
layout (location=1) in vec2 camPos;
layout (location=0) out vec4 outColor;

float log10(float x)
{
    return log(x) / log(10.0);
}

float satf(float x)
{
    return clamp(x, 0.0, 1.0);
}

vec2 satv(vec2 x)
{
    return clamp(x, vec2(0.0), vec2(1.0));
}

float max2(vec2 v)
{
    return max(v.x, v.y);
}

vec4 gridColor(vec2 uv, vec2 camPos)
{
    vec2 dudv = vec2(
        length(vec2(dFdx(uv.x), dFdy(uv.x))),
        length(vec2(dFdx(uv.y), dFdy(uv.y)))
    );

    float lodLevel = max(0.0, log10((length(dudv) * gridMinPixelsBetweenCells) / gridCellSize) + 1.0);
    float lodFade = fract(lodLevel);

    float lod0 = gridCellSize * pow(10.0, floor(lodLevel));
    float lod1 = lod0 * 10.0;
    float lod2 = lod1 * 10.0;

    dudv *= 4.0;

    float lod0a = max2(vec2(1.0) - abs(satv(mod(uv, lod0) / dudv) * 2.0 - vec2(1.0)));
    float lod1a = max2(vec2(1.0) - abs(satv(mod(uv, lod1) / dudv) * 2.0 - vec2(1.0)));
    float lod2a = max2(vec2(1.0) - abs(satv(mod(uv, lod2) / dudv) * 2.0 - vec2(1.0)));

    uv -= camPos;

    vec4 c = lod2a > 0.0 ? gridColorThick : lod1a > 0.0 ? mix(gridColorThick, gridColorThin, lodFade) : gridColorThin;

    float opacityFalloff = (1.0 - satf(length(uv) / gridSize));

    c.a *= (lod2a > 0.0 ? lod2a : lod1a > 0.0 ? lod1a : (lod0a * (1.0-lodFade))) * opacityFalloff;

    return c;
}

void main()
{
    outColor = gridColor(uv, camPos);
}
\end{lstlisting}
    \item light\_cube.vert\\
    The source of light is a simple cube, therefore the vertex shader contains a constant array of 36 vertices of the cube. The only calculation performed in this shader is MVP.
\begin{lstlisting}[language=c++, caption=Light cube vertex shader (./assets/shaders/light\_cube.vert)]
const vec3 cubeVertices[36] =
{
    {-1., -1., -1.},
    {-1., -1.,  1.},
    {-1.,  1.,  1.},
    ,,, (other 33 vertices)
};

void main()
{
    mat4 cameraMat = mat4(1.0);
    cameraMat[3] = vec4(ubo.camPos, 1.0);

    gl_Position =
        ubo.projMats[gl_ViewIndex] *
        ubo.viewMat[gl_ViewIndex] *
        cameraMat *
        vec4(pushConst.objPos + cubeVertices[gl_VertexIndex], 1.0);
}
\end{lstlisting}
    \item light\_cube.frag\\
    The source of light is a white lighting cube, so the returned value is \texttt{vec4(1.0)}
\begin{lstlisting}[language=c++, caption=Light cube fragment shader (./assets/shaders/light\_cube.frag)]
layout(location = 0) out vec4 outColor;

void main()
{
    outColor = vec4(1.0);
}
\end{lstlisting}
    \item normal\_lighting.vert\\
    \label{vert_normal_light}
    Normal lighting is the default method of objects lighting used in the project, as we didn't find it needed to implement textures and the simple one-color objects are not so representative as the idea of lighting the objects based on their normal vectors. Taking all of this into account, vertex shader beside doing MVP calculation passes to the \texttt{normal\_lighting.frag} normalized normal vector.
\begin{lstlisting}[language=c++, caption=Normal lighting vertex shader (./assets/shaders/normal\_lighting.vert)]
layout(location = 0) in vec3 inPos;
layout(location = 1) in vec3 inNormal;

layout(location = 0) out vec3 outColor;

void main()
{
    mat4 cameraMat = mat4(1.0);
    cameraMat[3] = vec4(commonUbo.camPos, 1.0);

    gl_Position =
        commonUbo.projMats[gl_ViewIndex] *
        commonUbo.viewMats[gl_ViewIndex] *
        cameraMat *
        individualUbo.modelMat *
        vec4(pushConst.objPos + inPos, 1.0);

    outColor = mat3(individualUbo.modelMat) * normalize(inNormal);
}
\end{lstlisting}
    \item normal\_lighting.frag\\
    The only thing the normal lighting fragment shader does, is interpreting the normalized normal vector as the color passed from \texttt{normal\_lighting.vert}.
    \label{frag_normal_light}
\begin{lstlisting}[language=c++, caption=Normal lighting fragment shader (./assets/shaders/normal\_lighting.frag)]
layout(location = 0) in vec3 inColor;
layout(location = 0) out vec4 outColor;

void main()
{
    outColor = vec4(inColor, 1.0);
}
\end{lstlisting}
    \item pbr.vert\\
    In the PBR vertex shader, there are not too many things to explain, besides MVP multiplication, coordinates of the vertex and its normal vertex are passed to the fragment shader. 
\begin{lstlisting}[language=c++, caption=PBR vertex shader (./assets/shaders/pbr.vert)]
layout (location = 0) out vec3 outWorldPos;
layout (location = 1) out vec3 outNormal;

void main()
{
    mat4 cameraMat = mat4(1.0);
    cameraMat[3] = vec4(commonUbo.camPos, 1.0);

    vec3 worldPos = inPos + pushConst.objPos;
    outWorldPos = worldPos;
    outNormal = mat3(individualUbo.modelMat) * inNormal;

    gl_Position =
        commonUbo.projMats[gl_ViewIndex] *
        commonUbo.viewMats[gl_ViewIndex] *
        cameraMat *
        individualUbo.modelMat *
        vec4(worldPos, 1.0);
}
\end{lstlisting}
    \item pbr.frag\\
    PBR shader is a pretty straightforward implementation of theory explained in theory part - \hyperref[sec:pbr]{\ref*{sec:pbr} Physical Based Rendering}.
\begin{lstlisting}[language=c++, caption=PBR fragment shader(./assets/shaders/pbr.frag)]
vec3 materialcolor()
{
    return vec3(material.r, material.g, material.b);
}

float D_GGX(float dotNH, float roughness)
{
    float alpha = roughness * roughness;
    float alpha2 = alpha * alpha;
    float denom = dotNH * dotNH * (alpha2 - 1.0) + 1.0;

    return alpha2 / (PI * denom*denom);
}

float G_SchlicksmithGGX(float dotNL, float dotNV, float roughness)
{
    float r = (roughness + 1.0);
    float k = (r*r) / 8.0;
    float GL = dotNL / (dotNL * (1.0 - k) + k);
    float GV = dotNV / (dotNV * (1.0 - k) + k);

    return GL * GV;
}

vec3 F_Schlick(float cosTheta, float metallic)
{
    vec3 F0 = mix(vec3(0.04), materialcolor(), metallic);
    vec3 F = F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);

    return F;
}

vec3 BRDF(vec3 L, vec3 V, vec3 N, float metallic, float roughness)
{
    vec3 H = normalize(V + L);
    float dotNV = max(dot(N, V), 0);
    float dotNL = max(dot(N, L), 0);
    float dotLH = max(dot(L, H), 0);
    float dotNH = max(dot(N, H), 0);

    vec3 lightColor = vec3(1.0);

    vec3 color = vec3(0.0);

    if (dotNL > 0.0)
    {
        float roughness = max(0.05, roughness);
        float D = D_GGX(dotNH, roughness);
        float G = G_SchlicksmithGGX(dotNL, dotNV, roughness);
        vec3 F = F_Schlick(dotNV, metallic);

        vec3 spec = D * F * G / (4.0 * dotNL * dotNV);

        color += spec * dotNL * lightColor;
    }

    return color;
}

void main()
{
    vec3 N = normalize(inNormal);

    vec3 temp = vec3(commonUbo.viewMats[gl_ViewIndex][3]);
    vec3 v1 = vec3(
        commonUbo.camPos.x + temp.x,
        commonUbo.camPos.y + temp.y,
        commonUbo.camPos.z + temp.z
        );
    vec3 V = normalize(-v1 - inWorldPos);

    vec3 Lo = vec3(0.0);
    for (int i = 0; i < lightsUbo.positions.length(); i++)
    {
        vec3 L = normalize(lightsUbo.positions[i] - inWorldPos);
        Lo += BRDF(L, V, N, material.metallic, material.roughness);
    };

    vec3 color = materialcolor() * 0.02;
    color += Lo;

    color = pow(color, vec3(0.4545));

    outColor = vec4(color, 1.0);
}
\end{lstlisting}
\end{itemize}